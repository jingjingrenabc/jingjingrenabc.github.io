<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Towards Flexible, Scalable, and Adaptive Multi-Modal Conditioned Face Synthesis">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Towards Flexible, Scalable, and Adaptive Multi-Modal Conditioned Face Synthesis.</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Towards Flexible, Scalable, and Adaptive Multi-Modal Conditioned Face Synthesis</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=wcuqACgAAAAJ&hl=zh-CN&oi=ao">Jingjing Ren</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?hl=zh-CN&user=KxYpmCYAAAAJ">Cheng Xu</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?hl=zh-CN&user=KWbcBucAAAAJ">Haoyu Chen</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=TD63QrsAAAAJ&hl=zh-CN&oi=ao">Xinran Qin</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://li-chongyi.github.io/">Chongyi Li</a><sup>4</sup>,
            </span>
            <span class="author-block">
              <a href="https://sites.google.com/site/indexlzhu/home">Lei Zhu</a><sup>1</sup>,
            </span>

          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>ROAS Thrust, The Hong Kong University of Science and Technology (Guangzhou),</span>
            <span class="author-block"><sup>2</sup>Centre of Smart Health, The Hong Kong Polytechnic University</span>
            <span class="author-block"><sup>3</sup>School of Cyber Science and Technology, Shenzhen Campus of Sun Yat-sen University</span>
            <span class="author-block"><sup>4</sup>School of Computer Science, Nankai University</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/google/nerfies"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- teaser -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="assets/teaser.jpg" style="width:1000px; margin-bottom:20px;"
                   alt="Teaser."/>
      <p>
        Our method's versatile synthesis capabilities, demonstrating high-fidelity facial image generation from a flexible combination of modalities including mask, text, sketch, lighting, expression, pose, and low-resolution images. Remarkably, these diverse face synthesis tasks are achieved within a single sampling process of a unified diffusion U-Net, demonstrating the method's efficiency and the seamless integration of multi-modal information.
      <p>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Recent progress in multi-modal conditioned face synthesis has enabled the creation of visually striking and accurately aligned facial images. 
Yet, current methods still  face issues with scalability, limited flexibility, and a one-size-fits-all approach to control strength, not accounting for the differing levels of conditional entropy, a measure of unpredictability in data given some condition, across modalities.
          </p>
          <p>
            To address these challenges, we introduce a novel uni-modal training approach with modal surrogates, coupled with an entropy-aware modal-adaptive modulation, to support flexible, scalable, and scalable multi-modal conditioned face synthesis network. 
            Our uni-modal training with modal surrogate that only leverage uni-modal data, use modal surrogate to decorate condition with modal-specific characteristic  and serve as linker for inter-modal collaboration , fully learns each modality control in face synthesis process as well as inter-modal collaboration. 
            The entropy-aware modal-adaptive modulation finely adjust diffusion noise according to modal-specific characteristics and given conditions, enabling well-informed step along denoising trajectory and ultimately leading to synthesis results of high fidelity and quality. 
            Our framework improves multi-modal face synthesis under various conditions, surpassing current methods in image quality and fidelity, as demonstrated by our thorough experimental results.            
          </p>

        </div>
      </div>
    </div>
    <!--/ Abstract. -->
</section>

<div id="spotlight-video">
  <div class="container is-max-desktop">
      <div class="column">
        <h2 class="title is-3">
          <div class="columns is-centered has-text-centered">
          <span class="a">Video Demo</span>
         
        </h2>
        <video id="dollyzoom"  autoplay controls muted loop playsinline  width="100%" >
          <source src="assets/video_demo.mp4"
                  type="video/mp4">
        </video>
    </div>
  </div>
</div>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Method</h2>
        <div class="content has-text-justified">
          <img src="assets/method.png" style="width:1000px; margin-bottom:20px;"
          alt="Teaser."/>

          <p>
            Uni-modal training with modal surrogate and entropy-aware modal-adaptive modulation mechanism. During training, we randomly sample uni-modal data, of which the condition is fused with its modal surrogate to learn modal-specific intrinsic and other modal surrogate to learn inter-modal collaboration. The fused features are sent to the diffusion U-Net to guide the de-noising process of the corrupted input image. The output noise is further modulated according to the condition features and UNet feature to adaptively adjust noise level given the conditions. The training process is provided in Algorithm 1.
          </p>

        </div>
      </div>
    </div>
</section>




<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="https://arxiv.org/abs/2312.06640" target="_blank">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/sczhou/Upscale-A-Video" target="_blank">
        <i class="fab fa-github"></i>
      </a>
      <a class="icon-link" href="https://youtu.be/b9J3lqiKnLM" target="_blank">
        <i class="fab fa-youtube"></i>
      </a>
    </div>

    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <div class="columns is-centered"><p>
            This website is build upon <a href="https://github.com/nerfies/nerfies.github.io" target="_blank">Nerfies </a>. Thanks for their sharing.
          </p></div>
        </div>
      </div>
    </div>

  </div>
</footer>

</body>
</html>
